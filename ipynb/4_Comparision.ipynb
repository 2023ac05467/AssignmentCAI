{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12adfe03",
   "metadata": {},
   "source": [
    "### Group 100 -  Conversational AI Assignment 2\n",
    "\n",
    "\n",
    "```\n",
    "1. Amit Kumar Sharma      2023ac05454       100%\n",
    "\n",
    "2. Mohammed Faisal Sait   2023aa05525       100%\n",
    "\n",
    "3. Chachiya Faiz Arif     2023ac05420       100%\n",
    "\n",
    "4. Parveen Kumar          2023ac05467       100%\n",
    "\n",
    "5. Sachchinda Nand Singh  2023ac05002       100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87637630",
   "metadata": {},
   "source": [
    "## 4.4 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3d25e",
   "metadata": {},
   "source": [
    "### Compare average inference speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6e2cf",
   "metadata": {},
   "source": [
    "### Comparison Summary: Fine-Tuned Model vs. RAG Model\n",
    "\n",
    "| Aspect                     | Fine-Tuned Model                          | RAG Model                                   |\n",
    "|----------------------------|-------------------------------------------|--------------------------------------------|\n",
    "| **Performance on Trained Data** | Performs well on question-answer pairs from the trained dataset. | Struggles with direct question-answer pairs from the trained dataset. |\n",
    "| **Handling Indirect Questions** | Limited ability to handle indirect or out-of-distribution questions. | Excels at answering indirect or out-of-distribution questions by leveraging external sources. |\n",
    "| **Inference Speed**        | Generally faster due to direct response generation. | Slower due to the use of multiple sources, ranking, and reranking processes. |\n",
    "| **Reasoning**              | Relies solely on the trained data, limiting flexibility. | Combines information from various sources, enhancing reasoning capabilities. |\n",
    "\n",
    "In summary, the fine-tuned model is ideal for scenarios requiring fast and accurate responses within the scope of its training data, while the RAG model is better suited for handling complex or indirect queries by leveraging external knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f517f",
   "metadata": {},
   "source": [
    "### Strengths and Trade-offs\n",
    "\n",
    "#### Strengths of RAG\n",
    "- **Adaptability**: Capable of handling a wide range of queries, including those outside the training data.\n",
    "- **Factual Grounding**: Leverages external knowledge sources to provide accurate and up-to-date information.\n",
    "\n",
    "#### Strengths of Fine-Tuning\n",
    "- **Fluency**: Generates responses that are coherent and well-structured within the scope of its training data.\n",
    "- **Efficiency**: Faster inference speed due to direct response generation without external lookups.\n",
    "\n",
    "#### Robustness to Irrelevant Queries\n",
    "- **RAG**: More robust to irrelevant or out-of-distribution queries by retrieving relevant context from external sources.\n",
    "- **Fine-Tuning**: Limited robustness as it relies solely on the training data, making it less effective for unexpected queries.\n",
    "\n",
    "#### Practical Trade-offs\n",
    "- **RAG**: Offers flexibility and reasoning capabilities at the cost of slower inference speed and increased computational complexity.\n",
    "- **Fine-Tuning**: Provides faster and more efficient responses but is constrained by the scope of its training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
